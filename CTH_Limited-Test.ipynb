{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c79c2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#streamlit run /Users/Ben/Library/CloudStorage/Dropbox/Python/OpenAI/Streamlit/CTH/Cth_Limited.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b706cba3",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c596b9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test test\n",
    "#Preliminary modules\n",
    "import base64 \n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import requests\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import *\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import pause\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import httplib2\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "from streamlit_gsheets import GSheetsConnection\n",
    "from streamlit.components.v1 import html\n",
    "import streamlit_ext as ste\n",
    "\n",
    "#NSWCaseLaw\n",
    "from nswcaselaw.search import Search\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "#Google\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "#Word\n",
    "import textract\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e2f0d98",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Get current directory\n",
    "current_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41324b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#today\n",
    "day = datetime.now().strftime(\"%-d\")\n",
    "month = datetime.now().strftime(\"%B\")\n",
    "year = datetime.now().strftime(\"%Y\")\n",
    "today = day + ' ' + month + ' ' + year\n",
    "today_in_nums = str(datetime.now())[0:10]\n",
    "today_month = day + ' ' + month\n",
    "today_words = datetime.now().strftime('%A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c07a68ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate placeholder list of errors\n",
    "errors_list = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6829541d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "#Create function for saving responses and results\n",
    "def convert_df_to_json(df):\n",
    "    return df.to_json(orient = 'split', compression = 'infer')\n",
    "\n",
    "def convert_df_to_csv(df):\n",
    "   return df.to_csv(index=False).encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d85b54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Title of webpage\n",
    "st.set_page_config(\n",
    "   page_title=\"The Empirical Legal Research Kickstarter (CTH)\",\n",
    "   page_icon=\"ðŸ§Š\",\n",
    "   layout=\"centered\",\n",
    "   initial_sidebar_state=\"collapsed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de1b875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create dataframe\n",
    "def create_df():\n",
    "\n",
    "    #submission time\n",
    "    timestamp = datetime.now()\n",
    "\n",
    "    #Personal info entries\n",
    "    \n",
    "    name = name_entry\n",
    "    email = email_entry\n",
    "    gpt_api_key = gpt_api_key_entry\n",
    "\n",
    "\n",
    "\n",
    "    #dates\n",
    "    \n",
    "    on_this_date = ''\n",
    "\n",
    "    if on_this_date_entry != 'None':\n",
    "\n",
    "        try:\n",
    "\n",
    "            on_this_date = on_this_date_entry.strftime('%d/%m/%Y') + on_this_date_entry.strftime('%d') + before_date_entry.strftime('%B').lower()[:3] + on_this_date_entry.strftime('Y')\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    \n",
    "    before_date = ''\n",
    "\n",
    "    if before_date_entry != 'None':\n",
    "\n",
    "        try:\n",
    "\n",
    "            before_date = str(before_date_entry.strftime('%d')) + str(before_date_entry.strftime('%B')).lower()[:3] + str(before_date_entry.strftime('%Y'))\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    after_date = ''\n",
    "\n",
    "    if after_date_entry != 'None':\n",
    "        \n",
    "        try:\n",
    "            after_date = str(after_date_entry.strftime('%d')) + str(after_date_entry.strftime('%B')).lower()[:3] + str(after_date_entry.strftime('%Y'))\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "\n",
    "    #Other entries\n",
    "    case_name_mnc = case_name_mnc_entry\n",
    "    judge =  judge_entry\n",
    "    reported_citation = reported_citation_entry\n",
    "    file_number = file_number_entry\n",
    "    npa = npa_entry\n",
    "    with_all_the_words = with_all_the_words_entry\n",
    "    with_at_least_one_of_the_words = with_at_least_one_of_the_words_entry\n",
    "    without_the_words = without_the_words_entry\n",
    "    phrase = phrase_entry\n",
    "    proximity = proximity_entry\n",
    "    legislation = legislation_entry\n",
    "    cases_cited = cases_cited_entry\n",
    "    catchwords = catchwords_entry \n",
    "    \n",
    "    #Judgment counter bound\n",
    "    \n",
    "    judgments_counter_bound_ticked = judgments_counter_bound_entry\n",
    "    if int(judgments_counter_bound_ticked) > 0:\n",
    "        judgments_counter_bound = 10\n",
    "    else:\n",
    "        judgments_counter_bound = 10000\n",
    "\n",
    "    #GPT choice and entry\n",
    "    gpt_activation_status = gpt_activation_entry\n",
    "    gpt_questions = gpt_questions_entry[0: 1000]\n",
    "\n",
    "    #metadata choice\n",
    "\n",
    "    meta_data_choice = meta_data_entry\n",
    "    \n",
    "    new_row = {'Processed': '',\n",
    "           'Timestamp': timestamp,\n",
    "           'Your name': name, \n",
    "           'Your email address': email, \n",
    "           'Your GPT API key': gpt_api_key, \n",
    "           'Case name or medium neutral citation': case_name_mnc, \n",
    "           'Judge' : judge, \n",
    "            'Reported citation' : reported_citation, \n",
    "            'File number': file_number,\n",
    "            'National practice area': npa,\n",
    "            'With all the words': with_all_the_words,\n",
    "            'With at least one of the words': with_at_least_one_of_the_words,\n",
    "            'Without the words': without_the_words,\n",
    "            'Phrase': phrase,\n",
    "            'Proximity': proximity,\n",
    "            'On this date': on_this_date,\n",
    "            'After date': after_date,\n",
    "            'Before date': before_date,\n",
    "            'Legislation': legislation,\n",
    "            'Cases cited': cases_cited,\n",
    "            'Catchwords' : catchwords, \n",
    "            'Metadata inclusion' : meta_data_choice,\n",
    "           'Maximum number of judgments': judgments_counter_bound, \n",
    "           'Enter your question(s) for GPT': gpt_questions, \n",
    "            'Tick to use GPT': gpt_activation_status \n",
    "          }\n",
    "\n",
    "    df_master_new = pd.DataFrame(new_row, index = [0])\n",
    "    \n",
    "#    df_master_new.to_json(current_dir + '/df_master.json', orient = 'split', compression = 'infer')\n",
    "#    df_master_new.to_excel(current_dir + '/df_master.xlsx', index=False)\n",
    "\n",
    "#    if len(df_master_new) > 0:\n",
    "        \n",
    "    return df_master_new\n",
    "\n",
    "#    else:\n",
    "#        return 'Error: spreadsheet of reponses NOT generated.' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b74f658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define format functions for headnotes choice, courts choice, and GPT questions\n",
    "\n",
    "#Create function to split a string into a list by line\n",
    "def split_by_line(x):\n",
    "    y = x.split('\\n')\n",
    "    for i in y:\n",
    "        if len(i) == 0:\n",
    "            y.remove(i)\n",
    "    return y\n",
    "\n",
    "#Create function to split a list into a dictionary for list items longer than 10 characters\n",
    "#Apply split_by_line() before the following function\n",
    "def GPT_label_dict(x_list):\n",
    "    GPT_dict = {}\n",
    "    for i in x_list:\n",
    "        if len(i) > 10:\n",
    "            GPT_index = x_list.index(i) + 1\n",
    "            i_label = 'GPT question ' + f'{GPT_index}'\n",
    "            GPT_dict.update({i_label: i})\n",
    "    return GPT_dict\n",
    "\n",
    "#Functions for tidying up\n",
    "\n",
    "#Tidy up hyperlink\n",
    "def link(x):\n",
    "    value = '=HYPERLINK(\"' + str(x) + '\")'\n",
    "    return value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b993cf",
   "metadata": {},
   "source": [
    "# Federal Courts search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42174f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function turning search terms to search results url\n",
    "def fca_search(case_name_mnc= '', \n",
    "               judge ='', \n",
    "               reported_citation ='', \n",
    "               file_number ='', \n",
    "               npa = '', \n",
    "               with_all_the_words = '', \n",
    "               with_at_least_one_of_the_words = '', \n",
    "               without_the_words = '', \n",
    "               phrase = '', \n",
    "               proximity = '', \n",
    "               on_this_date = '', \n",
    "               after_date = '', \n",
    "               before_date = '', \n",
    "               legislation = '', \n",
    "               cases_cited = '', \n",
    "               catchwords = ''):\n",
    "    base_url = \"https://search2.fedcourt.gov.au/s/search.html?collection=judgments&sort=date&meta_v_phrase_orsand=judgments%2FJudgments%2Ffca\"\n",
    "    params = {'meta_2' : case_name_mnc, \n",
    "              'meta_A' : judge, \n",
    "              'meta_z' : reported_citation, \n",
    "              'meta_3' : file_number, \n",
    "              'meta_n_phrase_orsand' : npa, \n",
    "              'query_sand' : with_all_the_words, \n",
    "              'query_or' : with_at_least_one_of_the_words, \n",
    "              'query_not' : without_the_words, \n",
    "              'query_phrase' : phrase, \n",
    "              'query_prox' : proximity, \n",
    "              'meta_d' : on_this_date, \n",
    "              'meta_d1' : after_date, \n",
    "              'meta_d2' : before_date, \n",
    "              'meta_7' : legislation, \n",
    "              'meta_4' : cases_cited, \n",
    "              'meta_B' : catchwords}\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    response.raise_for_status()\n",
    "    # Process the response (e.g., extract relevant information)\n",
    "    # Your code here...\n",
    "    return response.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf74ceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auxiliary list for getting more pages of search results\n",
    "further_page_ending_list = []\n",
    "for i in range(100):\n",
    "    further_page_ending = 20 + i\n",
    "    if ((str(further_page_ending)[-1] =='1') & (str(further_page_ending)[0] not in ['3', '5', '7', '9', '11'])):\n",
    "        further_page_ending_list.append(str(further_page_ending))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1882563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function turning search results url to links to judgments\n",
    "def search_results_to_judgment_links(url_search_results, judgment_counter_bound):\n",
    "    #Scrape webpage of search results\n",
    "    page = requests.get(url_search_results)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "\n",
    "    #Start counter\n",
    "\n",
    "    counter = 1\n",
    "    \n",
    "    # Get links of first 20 results\n",
    "    links_raw = soup.find_all(\"a\", href=re.compile(\"fca\"))\n",
    "    links = []\n",
    "    \n",
    "    for i in links_raw:\n",
    "        if (('title=' in str(i)) and (counter <=judgment_counter_bound)):\n",
    "            remove_title = str(i).split('\" title=')[0]\n",
    "            remove_leading_words = remove_title.replace('<a href=\"', '')\n",
    "            if 'a class=' not in remove_leading_words:\n",
    "                links.append(remove_leading_words)\n",
    "                counter = counter + 1\n",
    "\n",
    "    #Go beyond first 20 results\n",
    "\n",
    "    for ending in further_page_ending_list:\n",
    "        if counter <=judgment_counter_bound:\n",
    "            url_next_page = url_search_results + '&start_rank=' + f\"{ending}\"\n",
    "            page_judgment_next_page = requests.get(url_next_page)\n",
    "            soup_judgment_next_page = BeautifulSoup(page_judgment_next_page.content, \"lxml\")\n",
    "            links_next_page_raw = soup_judgment_next_page.find_all(\"a\", href=re.compile(\"fca\"))\n",
    "            links_next_page = []\n",
    "            for i in links_next_page_raw:\n",
    "                if 'title=' in str(i):\n",
    "                    remove_title = str(i).split('\" title=')[0]\n",
    "                    remove_leading_words = remove_title.replace('<a href=\"', '')\n",
    "                    if 'a class=' not in remove_leading_words:\n",
    "                        links.append(remove_leading_words)\n",
    "                        counter = counter + 1\n",
    "\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7de336ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#judgment url to word document\n",
    "#NOT in use\n",
    "def link_to_doc(url_judgment):\n",
    "    page_judgment = requests.get(url_judgment)\n",
    "    soup_judgment = BeautifulSoup(page_judgment.content, \"lxml\")\n",
    "    link_word_raw = soup_judgment.find_all('a', string=re.compile('Word'))\n",
    "    if len(link_word_raw)> 0:\n",
    "        link_to_word = str(link_word_raw).split('>')[0].replace('[<a href=\"', '')\n",
    "        return link_to_word\n",
    "    else:\n",
    "        return url_judgment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8f45add",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for turning a link to judgment to a judgment dictonary\n",
    "#NOT IN USE Too many problems\n",
    "def link_to_judgment_dict(url_judgment):\n",
    "    page_judgment = requests.get(url_judgment)\n",
    "    soup_judgment = BeautifulSoup(page_judgment.content, \"lxml\")\n",
    "    \n",
    "    #Get meta data\n",
    "    meta_data_all = str(soup_judgment).split('REASONS FOR JUDGMENT')[0].replace('\\\\n', '\\n\\n')\n",
    "    \n",
    "    #Get Judgment\n",
    "\n",
    "    judgment_paras_text_only = []\n",
    "    \n",
    "    judgment_raw = str(soup_judgment).split('REASONS FOR JUDGMENT')[1]\n",
    "    \n",
    "    judgment_raw_paras = judgment_raw.split('order=')\n",
    "    \n",
    "    for para_text_raw in judgment_raw_paras:\n",
    "        para_text = ''.join(para_text_raw.split('\">')[1:])\n",
    "        if len(para_text) > 0:\n",
    "            if para_text[0].isdigit():\n",
    "                para_text_clean = para_text.replace('</span>', '').replace('<span>', '').replace(\"\\xa0\", \" \").replace('<span style=\"font:7.0pt &amp;quot;Times New Roman', \"\").replace('</p><p class=\"00806350', '')\n",
    "                judgment_paras_text_only.append(para_text_clean)\n",
    "    \n",
    "    judgment_paras_final = ' \\n\\n PARAGRAPH NUMBER '.join(judgment_paras_text_only)\n",
    "    \n",
    "    judgment_paras_finally_final = 'PARAGRAPH NUMBER '+ judgment_paras_final.replace('\\\\n', '\\n\\n')\n",
    "    \n",
    "    #Orders\n",
    "    \n",
    "    #orders_very_raw = str(soup_judgment).split(\"DATE OF ORDER\")[1].split(\"REASONS FOR JUDGMENT\")[0]\n",
    "    #orders_list = []\n",
    "    #orders_raw_list = orders_raw.split('\">')\n",
    "    #for i in orders_raw_list:\n",
    "    #    each_order = i.split('</p>')[0]\n",
    "    #    if len(each_order) > 3:\n",
    "    #        orders_list.append(each_order)\n",
    "    \n",
    "    #Convert to dict\n",
    "    \n",
    "    #orders_text_raw = 'Order number ' + ' Order number '.join(orders_list)\n",
    "    #orders_text=orders_text_raw.replace('   ',' ').replace('  ',' ')\n",
    "    #judgment_dict = {\"metadata\" : '', \"orders\" : '', \"judgment\" : ''}\n",
    "    judgment_dict = {\"metadata\" : '', \"judgment\" : ''}\n",
    "    \n",
    "    judgment_dict[\"metadata\"] = meta_data_all\n",
    "    #judgment_dict[\"orders\"] = orders_text\n",
    "    judgment_dict[\"judgment\"] = judgment_paras_finally_final\n",
    "    \n",
    "    #judgment_json= json.dumps(judgment_dict)\n",
    "    return judgment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc54dcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert html link to dictionary \n",
    "#NOT IN USE Too many problems\n",
    "\n",
    "def link_to_dict(url_judgment):\n",
    "    page_judgment = requests.get(url_judgment)\n",
    "    soup_judgment = BeautifulSoup(page_judgment.content, \"lxml\")\n",
    "    text = soup_judgment.get_text()\n",
    "    judgment_dic = {'Hyperlink (click)': url_judgment, 'Judgment' : text}\n",
    "    \n",
    "    return judgment_dic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "beb67364",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert link to document to dictionary \n",
    "#NOT IN USE\n",
    "\n",
    "def doc_link_to_dict(link_to_doc):\n",
    "\n",
    "    court_counter = 0\n",
    "    \n",
    "    if '.docx' in link_to_doc:\n",
    "\n",
    "        file_name_raw = link_to_doc.split('.docx')[0]\n",
    "\n",
    "        for j in ['fcafc', 'FCAFC', 'fca', 'FCA']:\n",
    "\n",
    "            if ((j in file_name_raw) and (court_counter <1)):\n",
    "    \n",
    "                file_name = file_name_raw.split(j)[0][-4:] + j + file_name_raw.split(j)[1] + '.docx'\n",
    "    \n",
    "                urlretrieve(link_to_doc, file_name)\n",
    "\n",
    "                file_loc = current_dir + '/' + file_name\n",
    "\n",
    "                text = textract.process(file_loc)\n",
    "\n",
    "                text_list = str(text).split(\"\\\\x\")\n",
    "                \n",
    "                text_clean_list = []\n",
    "                \n",
    "                for x in text_list:\n",
    "                    if len(x)>2:\n",
    "                        x_clean = x[2:]\n",
    "                        text_clean_list.append(x_clean)\n",
    "                    \n",
    "                text_clean = ' '.join(text_clean_list).replace('\\\\n', '\\n')\n",
    "\n",
    "                court_counter = court_counter +1\n",
    "    \n",
    "    elif '.pdf' in link_to_doc:\n",
    "\n",
    "        for k in ['fcafc', 'FCAFC', 'fca', 'FCA']:\n",
    "\n",
    "            if ((k in file_name_raw) and (court_counter <1)):\n",
    "\n",
    "                file_name = file_name_raw.split(k)[0][-4:] + k + file_name_raw.split(k)[1] + '.pdf'\n",
    "\n",
    "                urlretrieve(link_to_doc, file_name)\n",
    "\n",
    "                file_loc = current_dir + '/' + file_name\n",
    "\n",
    "                text = textract.process(file_loc)\n",
    "\n",
    "                text_list = str(text).split(\"\\\\x\")\n",
    "                \n",
    "                text_clean_list = []\n",
    "                \n",
    "                for x in text_list:\n",
    "                    if len(x)>2:\n",
    "                        x_clean = x[2:]\n",
    "                        text_clean_list.append(x_clean)\n",
    "                    \n",
    "                text_clean = ' '.join(text_clean_list).replace('\\\\n', '\\n')\n",
    "\n",
    "                court_counter = court_counter +1\n",
    "\n",
    "    else:\n",
    "        file_name = 'Not working'\n",
    "        text_clean = 'Not working'\n",
    "        \n",
    "    judgment_dic = {'File name' : file_name, 'Hyperlink (click)': link_to_doc, 'Judgment' : text_clean}\n",
    "    \n",
    "    return judgment_dic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb432322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Meta labels\n",
    "#NOT IN USE, but works\n",
    "\n",
    "meta_labels = ['MNC', 'Year', 'Appeal', 'File_Number', 'Judge', 'Judgment_Dated', 'Distribution', 'Subject', 'Words_Phrases', 'Legislation', 'Cases_Cited', 'Division', 'NPA', 'Pages', 'All_Parties', 'Jurisdiction', 'Reported', 'Summary', 'Corrigenda', 'Parties', 'FileName', 'Asset_ID', 'Date.published']\n",
    "\n",
    "def meta_dict(judgment_url):\n",
    "    meta_dict = {'MNC' : '',  \n",
    "                 'Year' : '',  \n",
    "                 'Appeal' : '',  \n",
    "                 'File_Number' : '',  \n",
    "                 'Judge' : '',  \n",
    "                 'Judgment_Dated' : '',  \n",
    "                 'Distribution' : '',  \n",
    "                 'Subject' : '',  \n",
    "                 'Words_Phrases' : '',  \n",
    "                 'Legislation' : '',  \n",
    "                 'Cases_Cited' : '',  \n",
    "                 'Division' : '',  \n",
    "                 'NPA' : '',  \n",
    "                 'Pages' : '',  \n",
    "                 'All_Parties' : '',  \n",
    "                 'Jurisdiction' : '',  \n",
    "                 'Reported' : '',  \n",
    "                 'Summary' : '',  \n",
    "                 'Corrigenda' : '',  \n",
    "                 'Parties' : '',  'FileName' : '',  \n",
    "                 'Asset_ID' : '',  \n",
    "                 'Date.published' : ''\n",
    "                }\n",
    "    page = requests.get(judgment_url)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    meta_tags = soup.find_all(\"meta\")\n",
    "\n",
    "    if len(meta_tags)>0:\n",
    "        for tag_index in range(len(meta_tags)):\n",
    "            for tag_name in meta_labels:\n",
    "                if tag_name in str(meta_tags[tag_index]):\n",
    "                    meta_dict[tag_name] = meta_tags[tag_index].get(\"content\")\n",
    "    return meta_dict\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3d3a6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Meta labels and judgment combined\n",
    "#IN USE\n",
    "meta_labels = ['MNC', 'Year', 'Appeal', 'File_Number', 'Judge', 'Judgment_Dated', 'Distribution', 'Subject', 'Words_Phrases', 'Legislation', 'Cases_Cited', 'Division', 'NPA', 'Pages', 'All_Parties', 'Jurisdiction', 'Reported', 'Summary', 'Corrigenda', 'Parties', 'FileName', 'Asset_ID', 'Date.published']\n",
    "meta_labels_droppable = ['Year', 'Appeal', 'File_Number', 'Judge', 'Judgment_Dated', 'Distribution', 'Subject', 'Words_Phrases', 'Legislation', 'Cases_Cited', 'Division', 'NPA', 'Pages', 'All_Parties', 'Jurisdiction', 'Reported', 'Summary', 'Corrigenda', 'Parties', 'FileName', 'Asset_ID', 'Date.published']\n",
    "\n",
    "def meta_judgment_dict(judgment_url):\n",
    "    judgment_dict = {'Case name': '',\n",
    "                 'Medium neutral citation': '',\n",
    "                'Hyperlink (click)' : '', \n",
    "                'MNC' : '',  \n",
    "                 'Year' : '',  \n",
    "                 'Appeal' : '',  \n",
    "                 'File_Number' : '',  \n",
    "                 'Judge' : '',  \n",
    "                 'Judgment_Dated' : '',  \n",
    "                 'Distribution' : '',  \n",
    "                 'Subject' : '',  \n",
    "                 'Words_Phrases' : '',  \n",
    "                 'Legislation' : '',  \n",
    "                 'Cases_Cited' : '',  \n",
    "                 'Division' : '',  \n",
    "                 'NPA' : '',  \n",
    "                 'Pages' : '',  \n",
    "                 'All_Parties' : '',  \n",
    "                 'Jurisdiction' : '',  \n",
    "                 'Reported' : '',  \n",
    "                 'Summary' : '',  \n",
    "                 'Corrigenda' : '',  \n",
    "                 'Parties' : '',  'FileName' : '',  \n",
    "                 'Asset_ID' : '',  \n",
    "                 'Date.published' : '', \n",
    "                'Judgment' : ''\n",
    "                }\n",
    "\n",
    "    \n",
    "    #Attach hyperlink\n",
    "\n",
    "    judgment_dict['Hyperlink (click)'] = link(judgment_url)\n",
    "    \n",
    "    page = requests.get(judgment_url)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    meta_tags = soup.find_all(\"meta\")\n",
    "\n",
    "    #Attach meta tags\n",
    "    if len(meta_tags)>0:\n",
    "        for tag_index in range(len(meta_tags)):\n",
    "            for tag_name in meta_labels:\n",
    "                if tag_name in str(meta_tags[tag_index]):\n",
    "                    judgment_dict[tag_name] = meta_tags[tag_index].get(\"content\")\n",
    "\n",
    "    try:\n",
    "        judgment_dict['Case name'] = judgment_dict['MNC'].split('[')[0]\n",
    "        judgment_dict['Medium neutral citation'] = '[' + judgment_dict['MNC'].split('[')[1]\n",
    "        judgment_dict.pop('MNC')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #Attach Judgment\n",
    "\n",
    "    judgment_text = ''\n",
    "    \n",
    "    try:\n",
    "        judgment_removed_bottom = str(soup.get_text()).split('Translation Services')\n",
    "        judgment_raw_no_bottom = judgment_removed_bottom[0]\n",
    "        judgment_raw_paras = judgment_raw_no_bottom.split('REASONS FOR JUDGMENT')\n",
    "        judgment_text = ''.join(judgment_raw_paras[1:])\n",
    "    except:\n",
    "        judgment_text = str(soup.get_text())\n",
    "\n",
    "    judgment_dict['Judgment'] = judgment_text\n",
    "\n",
    "    #Check if gets taken to a PDF\n",
    "\n",
    "    if '.pdf' in judgment_url.lower():\n",
    "        judgment_dict['Case name'] = 'Not working because the judgment is in PDF.'\n",
    "    \n",
    "    return judgment_dict\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86747ecc",
   "metadata": {},
   "source": [
    "# GPT functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8adf0217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prior number of GPT uses is capped at 3 times.\n",
      "\n",
      "Questions for GPT are capped at 1000 characters.\n",
      "\n",
      "Number of judgments to scrape per request is capped at 10.\n",
      "\n",
      "The pause between judgment scraping is 5 second.\n"
     ]
    }
   ],
   "source": [
    "#Module and costs\n",
    "\n",
    "GPT_model = \"gpt-3.5-turbo-0125\"\n",
    "\n",
    "GPT_input_cost = 1/1000*0.0005 \n",
    "GPT_output_cost = 1/1000*0.0015\n",
    "\n",
    "#Upperbound on number of engagements with GPT\n",
    "\n",
    "GPT_use_bound = 3\n",
    "\n",
    "print(f\"\\nPrior number of GPT uses is capped at {GPT_use_bound} times.\")\n",
    "\n",
    "#Upperbound on the length of questions for GPT\n",
    "\n",
    "answers_characters_bound = 1000\n",
    "\n",
    "print(f\"\\nQuestions for GPT are capped at {answers_characters_bound} characters.\")\n",
    "\n",
    "#Upperbound on number of judgments to scrape\n",
    "\n",
    "judgments_counter_bound = 10\n",
    "\n",
    "print(f\"\\nNumber of judgments to scrape per request is capped at {judgments_counter_bound}.\")\n",
    "\n",
    "#Pause between judgment scraping\n",
    "\n",
    "scraper_pause = 5\n",
    "\n",
    "print(f\"\\nThe pause between judgment scraping is {scraper_pause} second.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4c3e181",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function to determine eligibility for GPT use\n",
    "\n",
    "#Define a list of privileged email addresses with unlimited GPT uses\n",
    "\n",
    "privileged_emails = ['ben.chen@sydney.edu.au', \n",
    "                     'nehc.neb@gmail.com', \n",
    "                     'natalie.silver@sydney.edu.au', \n",
    "                     'kimberlee.weatherall@sydney.edu.au',\n",
    "                     'jeffrey.gordon@sydney.edu.au', \n",
    "                     'michael.j.crawford@sydney.edu.au'\n",
    "                     'genevieve.grant@monash.edu', \n",
    "                     'genevieve.grant@monash.edu.au', \n",
    "                     'm.legg@unsw.edu.au'\n",
    "                    ]\n",
    "\n",
    "def prior_GPT_uses(email_address, df_online):\n",
    "    # df_online variable should be the online df_online\n",
    "    prior_use_counter = 0\n",
    "    for i in df_online.index:\n",
    "        if ((df_online.loc[i, \"Your email address\"] == email_address) \n",
    "            and (int(df_online.loc[i, \"Tick to use GPT\"]) > 0) \n",
    "            and (len(df_online.loc[i, \"Processed\"])>0)\n",
    "           ):\n",
    "            prior_use_counter += 1\n",
    "    if email_address in privileged_emails:\n",
    "        return 0\n",
    "    else:\n",
    "        return prior_use_counter\n",
    "\n",
    "#Define function to check whether email is educational or government\n",
    "def check_edu_gov(email_address):\n",
    "    #Return 1 if educational or government, return 0 otherwise\n",
    "    end=email_address.split('@')[1]\n",
    "    if (('.gov' in end) or ('.edu' in end) or ('.ac' in end)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52c78273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokens estimate preliminaries\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "#Tokens estimate function\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "#Define judgment input function for JSON approach\n",
    "\n",
    "#Token limit covering both GTP input and GPT output is 16385, each token is about 4 characters\n",
    "characters_limit_half = int((16385*4)/2-1500)\n",
    "tokens_cap = int(16385 - 1500)\n",
    "\n",
    "def judgment_prompt_json(judgment_json):\n",
    "                \n",
    "    judgment_content = \"Based on the metadata and judgment in the following JSON: \" + str(judgment_json) + \", \"\n",
    "\n",
    "    judgment_content_tokens = num_tokens_from_string(judgment_content, \"cl100k_base\")\n",
    "    \n",
    "    if judgment_content_tokens <= tokens_cap:\n",
    "        \n",
    "        return judgment_content\n",
    "\n",
    "    else:\n",
    "        \n",
    "        meta_data_len = judgment_content_tokens - num_tokens_from_string(judgment_json['Judgment'], \"cl100k_base\")\n",
    "        \n",
    "        judgment_chars_capped = int((tokens_cap - meta_data_len)*4)\n",
    "        \n",
    "        judgment_string_trimmed = judgment_json['Judgment'][ :int(judgment_chars_capped/2)] + judgment_json['Judgment'][-int(judgment_chars_capped/2): ]\n",
    "\n",
    "        judgment_json[\"Judgment\"] = judgment_string_trimmed     \n",
    "        \n",
    "        judgment_content_capped = \"Based on the metadata and judgment in the following JSON: \" + str(judgment_json) + \",\"\n",
    "        \n",
    "        return judgment_content_capped\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7826d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define system role content for GPT\n",
    "role_content = 'You are a legal research assistant helping an academic researcher to answer questions about a public judgment. You will be provided with the judgment and metadata in string form. Please answer questions based only on information contained in the judgment and metadata. Where your answer comes from a specific paragraph in the judgment, provide the paragraph number as part of your answer. If you cannot answer any of the questions based on the judgment or metadata, do not make up information, but instead write \"answer not found\".'\n",
    "\n",
    "intro_for_GPT = [{\"role\": \"system\", \"content\": role_content}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eaf15a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define GPT answer function for answers in json form, YES TOKENS\n",
    "#IN USE\n",
    "\n",
    "def GPT_json_tokens(questions_json, judgment_json, API_key):\n",
    "    #'question_json' variable is a json of questions to GPT\n",
    "    #'jugdment' variable is a judgment_json   \n",
    "\n",
    "    \n",
    "    judgment_for_GPT = [{\"role\": \"user\", \"content\": judgment_prompt_json(judgment_json) + 'you will be given questions to answer in JSON form.'}]\n",
    "        \n",
    "    #Create answer format\n",
    "    \n",
    "    q_keys = [*questions_json]\n",
    "    \n",
    "    answers_json = {}\n",
    "    \n",
    "    for q_index in q_keys:\n",
    "        answers_json.update({q_index: 'Your answer to the question with index ' + q_index + '. State specific paragraph numbers in the judgment or specific sections in the metadata.'})\n",
    "    \n",
    "    #Create questions, which include the answer format\n",
    "    \n",
    "    question_for_GPT = [{\"role\": \"user\", \"content\": str(questions_json).replace(\"\\'\", '\"') + ' Give responses in the following JSON form: ' + str(answers_json).replace(\"\\'\", '\"')}]\n",
    "    \n",
    "    #Create messages in one prompt for GPT\n",
    "    messages_for_GPT = intro_for_GPT + judgment_for_GPT + question_for_GPT\n",
    "    \n",
    "#   return messages_for_GPT\n",
    "\n",
    "            \n",
    "    #os.environ[\"OPENAI_API_KEY\"] = API_key\n",
    "\n",
    "    openai.api_key = API_key\n",
    "    \n",
    "    #client = OpenAI()\n",
    "    \n",
    "    try:\n",
    "        #completion = client.chat.completions.create(\n",
    "        completion = openai.chat.completions.create(\n",
    "            model=GPT_model,\n",
    "            messages=messages_for_GPT, \n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        \n",
    "#        return completion.choices[0].message.content #This gives answers as a string containing a dictionary\n",
    "        \n",
    "        #To obtain a json directly, use below\n",
    "        answers_dict = json.loads(completion.choices[0].message.content)\n",
    "        \n",
    "        #Obtain tokens\n",
    "        output_tokens = completion.usage.completion_tokens\n",
    "        \n",
    "        prompt_tokens = completion.usage.prompt_tokens\n",
    "        \n",
    "        return [answers_dict, output_tokens, prompt_tokens]\n",
    "\n",
    "    except Exception as error:\n",
    "        \n",
    "        for q_index in q_keys:\n",
    "            answers_json[q_index] = error\n",
    "        \n",
    "        return [answers_json, 0, 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c44d5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define GPT function for each respondent's dataframe, index by judgment then question, with input and output tokens given by GPT itself\n",
    "#IN USE\n",
    "\n",
    "#The following function DOES NOT check for existence of questions for GPT\n",
    "    # To so check, active line marked as #*\n",
    "def engage_GPT_json_tokens(questions_json, df_individual, GPT_activation, API_key):\n",
    "    # Variable questions_json refers to the json of questions\n",
    "    # Variable df_individual refers to each respondent's df\n",
    "    # Variable activation refers to status of GPT activation (real or test)\n",
    "    # The output is a new JSON for the relevant respondent with new columns re:\n",
    "        # \"Judgment length in tokens (up to 15635 given to GPT)\"\n",
    "        # 'GPT cost estimate (USD excl GST)'\n",
    "        # 'GPT time estimate (seconds)'\n",
    "        # GPT questions/answers\n",
    "\n",
    "    #os.environ[\"OPENAI_API_KEY\"] = API_key\n",
    "\n",
    "    openai.api_key = API_key\n",
    "    \n",
    "    #client = OpenAI()\n",
    "    \n",
    "    question_keys = [*questions_json]\n",
    "    \n",
    "    for judgment_index in df_individual.index:\n",
    "        \n",
    "        judgment_json = df_individual.to_dict('index')[judgment_index]\n",
    "        \n",
    "        #Calculate and append number of tokens of judgment, regardless of whether given to GPT\n",
    "        judgment_tokens = num_tokens_from_string(str(judgment_json), \"cl100k_base\")\n",
    "        df_individual.loc[judgment_index, \"Judgment length in tokens (up to 15635 given to GPT)\"] = judgment_tokens       \n",
    "\n",
    "        #Indicate whether judgment truncated\n",
    "        \n",
    "        df_individual.loc[judgment_index, \"Judgment truncated (if given to GPT)?\"] = ''       \n",
    "        \n",
    "        if judgment_tokens <= characters_limit_half*2/4:\n",
    "            \n",
    "            df_individual.loc[judgment_index, \"Judgment truncated (if given to GPT)?\"] = 'No'\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            df_individual.loc[judgment_index, \"Judgment truncated (if given to GPT)?\"] = 'Yes'\n",
    "\n",
    "        #Create columns for respondent's GPT cost, time\n",
    "        df_individual.loc[judgment_index, 'GPT cost estimate (USD excl GST)'] = ''\n",
    "        df_individual.loc[judgment_index, 'GPT time estimate (seconds)'] = ''\n",
    "                \n",
    "        #Calculate GPT start time\n",
    "\n",
    "        GPT_start_time = datetime.now()\n",
    "\n",
    "        #Depending on activation status, apply GPT_json function to each judgment, gives answers as a string containing a dictionary\n",
    "\n",
    "        if int(GPT_activation) > 0:\n",
    "            GPT_output_list = GPT_json_tokens(questions_json, judgment_json, API_key) #Gives [answers as a JSON, output tokens, input tokens]\n",
    "            answers_dict = GPT_output_list[0]\n",
    "        \n",
    "        else:\n",
    "            answers_dict = {}    \n",
    "            for q_index in question_keys:\n",
    "                #Increases judgment index by 2 to ensure consistency with Excel spreadsheet\n",
    "                answer = 'Placeholder answer for ' + ' judgment ' + str(int(judgment_index) + 2) + ' ' + str(q_index)\n",
    "                answers_dict.update({q_index: answer})\n",
    "            \n",
    "            #Own calculation of GPT costs for Placeholder answer fors\n",
    "\n",
    "            #Calculate capped judgment tokens\n",
    "\n",
    "            judgment_capped_tokens = num_tokens_from_string(judgment_prompt_json(judgment_json), \"cl100k_base\")\n",
    "\n",
    "            #Calculate questions tokens and cost\n",
    "\n",
    "            questions_tokens = num_tokens_from_string(str(questions_json), \"cl100k_base\")\n",
    "\n",
    "            #Calculate other instructions' tokens\n",
    "\n",
    "            other_instructions = role_content + 'you will be given questions to answer in JSON form.' + ' Give responses in the following JSON form: '\n",
    "\n",
    "            other_tokens = num_tokens_from_string(other_instructions, \"cl100k_base\") + len(question_keys)*num_tokens_from_string(\"GPT question x:  Your answer to the question with index GPT question x. State specific paragraph numbers in the judgment or specific sections in the metadata.\", \"cl100k_base\")\n",
    "\n",
    "            #Calculate number of tokens of answers\n",
    "            answers_tokens = num_tokens_from_string(str(answers_dict), \"cl100k_base\")\n",
    "\n",
    "            input_tokens = judgment_capped_tokens + questions_tokens + other_tokens\n",
    "            \n",
    "            GPT_output_list = [answers_dict, answers_tokens, input_tokens]\n",
    "\n",
    "        #Create GPT question headings and append answers to individual spreadsheets\n",
    "\n",
    "        for question_index in question_keys:\n",
    "            question_heading = question_index + ': ' + questions_json[question_index]\n",
    "            df_individual.loc[judgment_index, question_heading] = answers_dict[question_index]\n",
    "\n",
    "        #Calculate and append GPT finish time and time difference to individual df\n",
    "        GPT_finish_time = datetime.now()\n",
    "        \n",
    "        GPT_time_difference = GPT_finish_time - GPT_start_time\n",
    "\n",
    "        df_individual.loc[judgment_index, 'GPT time estimate (seconds)'] = GPT_time_difference.total_seconds()\n",
    "\n",
    "        #Calculate GPT costs\n",
    "\n",
    "        GPT_cost = GPT_output_list[1]*GPT_output_cost + GPT_output_list[2]*GPT_input_cost\n",
    "\n",
    "        #Calculate and append GPT cost to individual df\n",
    "        df_individual.loc[judgment_index, 'GPT cost estimate (USD excl GST)'] = GPT_cost\n",
    "    \n",
    "    return df_individual\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49b19856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain parameters\n",
    "\n",
    "def run(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['Enter your question(s) for GPT'] = df_master['Enter your question(s) for GPT'][0: answers_characters_bound].apply(split_by_line)\n",
    "    df_master['questions_json'] = df_master['Enter your question(s) for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "    \n",
    "    #Conduct search\n",
    "    \n",
    "    url_search_results = fca_search(case_name_mnc = df_master.loc[0, 'Case name or medium neutral citation'],\n",
    "                     judge = df_master.loc[0, 'Judge'], \n",
    "                     reported_citation = df_master.loc[0, 'Reported citation'],\n",
    "                     file_number  = df_master.loc[0, 'File number'],\n",
    "                     npa = df_master.loc[0, 'National practice area'], \n",
    "                     with_all_the_words  = df_master.loc[0, 'With all the words'], \n",
    "                     with_at_least_one_of_the_words = df_master.loc[0, 'With at least one of the words'],\n",
    "                     without_the_words = df_master.loc[0, 'Without the words'],\n",
    "                     phrase  = df_master.loc[0, 'Phrase'], \n",
    "                     proximity = df_master.loc[0, 'Proximity'], \n",
    "                     on_this_date = df_master.loc[0, 'On this date'], \n",
    "                     after_date = df_master.loc[0, 'After date'], \n",
    "                     before_date = df_master.loc[0, 'Before date'], \n",
    "                     legislation = df_master.loc[0, 'Legislation'], \n",
    "                     cases_cited = df_master.loc[0, 'Cases cited'], \n",
    "                     catchwords = df_master.loc[0, 'Catchwords'] \n",
    "                    )\n",
    "        \n",
    "    judgments_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "\n",
    "    judgments_links = search_results_to_judgment_links(url_search_results, judgments_counter_bound)\n",
    "\n",
    "    for link in judgments_links:\n",
    "\n",
    "        judgment_dict = meta_judgment_dict(link)\n",
    "\n",
    "#        meta_data = meta_dict(link)  \n",
    "#        doc_link = link_to_doc(link)\n",
    "#        judgment_dict = doc_link_to_dict(doc_link)\n",
    "#        judgment_dict = link_to_dict(link)\n",
    "#        judgments_all_info = { **meta_data, **judgment_dict}\n",
    "#        judgments_file.append(judgments_all_info)\n",
    "        judgments_file.append(judgment_dict)\n",
    "        pause.seconds(5)\n",
    "    \n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "    \n",
    "    #Rename column titles\n",
    "    \n",
    "#    try:\n",
    "#        df_individual['Hyperlink (double click)'] = df_individual['Hyperlink'].apply(link)\n",
    "#        df_individual.pop('Hyperlink')\n",
    "#    except:\n",
    "#        pass\n",
    "    \n",
    "    #Instruct GPT\n",
    "    \n",
    "    API_key = df_master.loc[0, 'Your GPT API key'] \n",
    "    \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Tick to use GPT'])\n",
    "\n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "            \n",
    "    #Engage GPT\n",
    "    df_updated = engage_GPT_json_tokens(questions_json, df_individual, GPT_activation, API_key)\n",
    "\n",
    "    df_updated.pop('Judgment')\n",
    "\n",
    "    if int(df_master.loc[0, 'Metadata inclusion']) == 0:\n",
    "        for meta_label in meta_labels_droppable:\n",
    "            try:\n",
    "                df_updated.pop(meta_label)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    return df_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b049846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_url(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "    \n",
    "    #Combining catchwords into new column\n",
    "    \n",
    "    #Conduct search\n",
    "    \n",
    "    url = fca_search(case_name_mnc = df_master.loc[0, 'Case name or medium neutral citation'],\n",
    "                     judge = df_master.loc[0, 'Judge'], \n",
    "                     reported_citation = df_master.loc[0, 'Reported citation'],\n",
    "                     file_number  = df_master.loc[0, 'File number'],\n",
    "                     npa = df_master.loc[0, 'National practice area'], \n",
    "                     with_all_the_words  = df_master.loc[0, 'With all the words'], \n",
    "                     with_at_least_one_of_the_words = df_master.loc[0, 'With at least one of the words'],\n",
    "                     without_the_words = df_master.loc[0, 'Without the words'],\n",
    "                     phrase  = df_master.loc[0, 'Phrase'], \n",
    "                     proximity = df_master.loc[0, 'Proximity'], \n",
    "                     on_this_date = df_master.loc[0, 'On this date'], \n",
    "                     after_date = df_master.loc[0, 'After date'], \n",
    "                     before_date = df_master.loc[0, 'Before date'], \n",
    "                     legislation = df_master.loc[0, 'Legislation'], \n",
    "                     cases_cited = df_master.loc[0, 'Cases cited'], \n",
    "                     catchwords = df_master.loc[0, 'Catchwords'] \n",
    "                    )\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3501d9f",
   "metadata": {},
   "source": [
    "# Streamlit form, functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "edfbbdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to open url\n",
    "def open_page(url):\n",
    "    open_script= \"\"\"\n",
    "        <script type=\"text/javascript\">\n",
    "            window.open('%s', '_blank').focus();\n",
    "        </script>\n",
    "    \"\"\" % (url)\n",
    "    html(open_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff6d49bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 14:05:52.256 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/Ben/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-03-07 14:05:52.257 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n"
     ]
    }
   ],
   "source": [
    "#Create form\n",
    "\n",
    "with st.form(\"GPT_input_form\") as df_responses:\n",
    "    st.title(\"The Empirical Legal Research Kickstarter\")\n",
    "    st.header(\"A Federal Court Pilot\")\n",
    "    \n",
    "    st.markdown(\"\"\"The Empirical Legal Research Kickstarter is a computer program designed to help kickstart empirical research involving judgments. It automates many costly, time-consuming and mundane tasks in empirical research.\n",
    "\n",
    "The Federal Court pilot version can automatically\n",
    "\n",
    "(1) search for and collect select judgments of the Federal Court of Australia, including the Full Court; \n",
    "\n",
    "(2) extract and code the judgment metadata; and\n",
    "\n",
    "(2) use GPT â€” a generative AI â€” as a research assistant to answer your questions about each judgment.\n",
    "\n",
    "**Complete this form to kickstart your project!**\n",
    "\"\"\")\n",
    "    st.caption('The Empirical Legal Research Kickstarter is the joint effort of Mike Lynch and Xinwei Luo of Sydney Informatics Hub and Ben Chen of Sydney Law School. It is partially funded by a University of Sydney Research Accelerator (SOAR) Prize awarded to Ben in 2022. Please send any enquiries to Ben at ben.chen@sydney.edu.au.')\n",
    "\n",
    "    st.header(\"Your information\")\n",
    "#    st.markdown(\"\"\"You must enter an API key if you wish to use GPT to analyse more than 10 judgments. \n",
    "#To obtain an API key, first sign up for an account with OpenAI at \n",
    "#https://platform.openai.com/signup. You can then find your API key at https://platform.openai.com/api-keys.\n",
    "#\"\"\")\n",
    "    name_entry = st.text_input(\"Your name\")\n",
    "    email_entry = st.text_input(\"Your email address\")\n",
    "#    gpt_api_key_entry = st.text_input(\"Your GPT API key\")\n",
    "\n",
    "    #Search terms\n",
    "\n",
    "    st.header(\"Judgment Search Criteria\")\n",
    "    \n",
    "    st.markdown(\"\"\"This program will collect (ie scrape) the first 10 judgments satisfying your search terms.\n",
    "\n",
    "For search tips, please visit the Federal Court Digital Law Library at https://www.fedcourt.gov.au/digital-law-library/judgments/search. This section mimics their judgments search function.\n",
    "\"\"\")\n",
    "    st.caption('During the pilot stage, the number of judgments to scrape is capped. Please reach out to Ben at ben.chen@sydney.edu.au should you wish to cover more judgments, courts, or tribunals.')\n",
    "    \n",
    "    st.subheader(\"Your Search Terms\")\n",
    "\n",
    "    catchwords_entry = st.text_input('Catchwords')\n",
    "\n",
    "    legislation_entry = st.text_input('Legislation')\n",
    "\n",
    "    cases_cited_entry = st.text_input('Cases cited')\n",
    "\n",
    "    case_name_mnc_entry = st.text_input(\"Case name or medium neutral citation\")\n",
    "    \n",
    "    judge_entry = st.text_input('Judge')\n",
    "\n",
    "    reported_citation_entry = st.text_input('Reported citation')\n",
    "\n",
    "    file_number_entry = st.text_input('File number')\n",
    "\n",
    "    npa_entry = st.text_input('National practice area')\n",
    "\n",
    "    \n",
    "    with_all_the_words_entry = st.text_input('With ALL the words')\n",
    "\n",
    "    with_at_least_one_of_the_words_entry = st.text_input('With at least one of the words')\n",
    "\n",
    "    without_the_words_entry = st.text_input('Without the words')\n",
    "\n",
    "    phrase_entry = st.text_input('Phrase')\n",
    "\n",
    "    proximity_entry  = st.text_input('Proximity')\n",
    "\n",
    "    on_this_date_entry = st.date_input('On this date', value = None, format=\"DD/MM/YYYY\")\n",
    "\n",
    "    after_date_entry = st.date_input('After date', value = None, format=\"DD/MM/YYYY\")\n",
    "\n",
    "    st.caption('Relatively earlier judgments will not be collected if they are available in PDF only. For information about judgment availability, please visit https://www.fedcourt.gov.au/digital-law-library/judgments/judgments-faq.')\n",
    "\n",
    "    before_date_entry = st.date_input('Before date', value = None, format=\"DD/MM/YYYY\")\n",
    "    \n",
    "    judgments_counter_bound_entry = judgments_counter_bound\n",
    "\n",
    "    st.markdown(\"\"\"You can preview your search results after you have entered some search terms.\n",
    "    \"\"\")\n",
    "    \n",
    "    preview_button = st.form_submit_button('Preview what you will find (in a popped up window)')\n",
    "\n",
    "    st.header(\"Judgment Metadata Collection\")\n",
    "    \n",
    "    st.markdown(\"\"\"Would you like to obtain judgment metadata? Such data include the name of the judge, the decision date and so on. \n",
    "    \n",
    "Case names and medium neutral citations are always included with your results.\n",
    "\"\"\")\n",
    "    \n",
    "    meta_data_entry = st.checkbox('Tick to include metadata in your results', value = False)\n",
    "\n",
    "    st.header(\"Use GPT as Your Research Assistant\")\n",
    "\n",
    "    st.markdown(\"**You have three (3) opportunities to engage with GPT through the Empirical Legal Research Kickstarter. Would you like to use one (1) of these opportunities now?**\")\n",
    "\n",
    "    gpt_activation_entry = st.checkbox('Tick to use GPT', value = False)\n",
    "\n",
    "    st.caption(\"Released by OpenAI, GPT is a family of large language models (ie a generative AI that works on language). Answers to your questions will be generated by model gpt-3.5-turbo-0125. Due to a technical limitation, the model will be instructed to 'read' up to approximately 11,726 words from each judgment.\")\n",
    "\n",
    "    st.markdown(\"\"\"Please consider trying the Empirical Legal Research Kickstarter without asking GPT any questions first. You can, for instance, obtain the judgments satisfying your search criteria and extract information from the judgment headnotes without using GPT.\n",
    "\"\"\")\n",
    "\n",
    "    st.caption(\"Engagement with GPT is costly and funded by a grant.  Ben's own experience suggests that it costs approximately USD \\$0.003-\\$0.008 (excl GST) per judgment. The exact cost for answering a question about a judgment depends on the length of the question, the length of the judgment, and the length of the answer produced (as elaborated at https://openai.com/pricing for model gpt-3.5-turbo-0125). You will be given ex-post cost estimates.\")\n",
    "\n",
    "    st.subheader(\"Enter your question(s) for GPT\")\n",
    "    \n",
    "    st.markdown(\"\"\"You may enter one or more questions. **Please enter one question per line or per paragraph.**\n",
    "\n",
    "GPT is instructed to avoid giving answers which cannot be obtained from the relevant judgment itself. This is to minimise the risk of giving incorrect information (ie hallucination).\n",
    "\n",
    "You may enter at most 1000 characters here.\n",
    "    \"\"\")\n",
    "\n",
    "    gpt_questions_entry = st.text_area(\"\", height= 200, max_chars=1000) \n",
    "\n",
    "    st.header(\"Consent\")\n",
    "\n",
    "    st.markdown(\"\"\"By submitting this form, you agree that the data and/or information this form provides will be temporarily stored on one or more of Ben Chen's electronic devices and/or one or more remote servers for the purpose of producing an output containing data in relation to judgments. Any such data and/or information may also be given to GPT for the same purpose should you choose to use GPT.\n",
    "\n",
    "If you do not agree, then please feel free to close this form. Any data or information this form provides will neither be received by Ben Chen nor be sent to GPT.\n",
    "\"\"\")\n",
    "    \n",
    "    consent =  st.checkbox('Yes, I agree.', value = False)\n",
    "\n",
    "    st.header(\"Next Steps\")\n",
    "\n",
    "    st.markdown(\"\"\"**You can submit this form to run the Empirical Legal Research Kickstarter.** The estimated waiting time to get your results is 10-20 seconds per judgment.\n",
    "\n",
    "You can also download a record of your responeses.\n",
    "    \n",
    "\"\"\")\n",
    "\n",
    "    run_button = st.form_submit_button('SUBMIT this form')\n",
    "\n",
    "    keep_button = st.form_submit_button('DOWNLOAD your responses')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be10c5b",
   "metadata": {},
   "source": [
    "# Save and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "647ed4c0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if preview_button:\n",
    "\n",
    "    gpt_api_key_entry = ''\n",
    "\n",
    "    df_master = create_df()\n",
    "\n",
    "    judgments_url =  fca_search(case_name_mnc = df_master.loc[0, 'Case name or medium neutral citation'],\n",
    "                     judge = df_master.loc[0, 'Judge'], \n",
    "                     reported_citation = df_master.loc[0, 'Reported citation'],\n",
    "                     file_number  = df_master.loc[0, 'File number'],\n",
    "                     npa = df_master.loc[0, 'National practice area'], \n",
    "                     with_all_the_words  = df_master.loc[0, 'With all the words'], \n",
    "                     with_at_least_one_of_the_words = df_master.loc[0, 'With at least one of the words'],\n",
    "                     without_the_words = df_master.loc[0, 'Without the words'],\n",
    "                     phrase  = df_master.loc[0, 'Phrase'], \n",
    "                     proximity = df_master.loc[0, 'Proximity'], \n",
    "                     on_this_date = df_master.loc[0, 'On this date'], \n",
    "                     after_date = df_master.loc[0, 'After date'], \n",
    "                     before_date = df_master.loc[0, 'Before date'], \n",
    "                     legislation = df_master.loc[0, 'Legislation'], \n",
    "                     cases_cited = df_master.loc[0, 'Cases cited'], \n",
    "                     catchwords = df_master.loc[0, 'Catchwords'] \n",
    "                    )\n",
    "\n",
    "    open_page(judgments_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0806a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_button:\n",
    "\n",
    "    #Using own GPT\n",
    "\n",
    "    gpt_api_key_entry = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "\n",
    "    #Create spreadsheet of responses\n",
    "    df_master = create_df()\n",
    "\n",
    "    #Obtain google spreadsheet\n",
    "\n",
    "    conn = st.connection(\"gsheets\", type=GSheetsConnection)\n",
    "    google_record_url = \"https://docs.google.com/spreadsheets/d/1Mlz_QyDl5fxoFiEgBXxqc2BOXJh8gognrBpr-4ML4_Q/edit#gid=1420440228\"\n",
    "    df_google = conn.read(spreadsheet=google_record_url)\n",
    "    df_google = df_google.fillna('')\n",
    "    df_google=df_google[df_google[\"Processed\"]!='']\n",
    "\n",
    "\n",
    "    if int(consent) == 0:\n",
    "        st.write(\"You must click on 'Yes, I agree.' to run the Empirical Legal Research Kickstarter.\")\n",
    "\n",
    "    elif (('@' not in df_master.loc[0, 'Your email address']) & (int(df_master.loc[0][\"Tick to use GPT\"]) > 0)):\n",
    "        st.write('You must enter a valid email address to use GPT')\n",
    "\n",
    "    elif ((int(df_master.loc[0][\"Tick to use GPT\"]) > 0) & (prior_GPT_uses(df_master.loc[0, \"Your email address\"], df_google) >= GPT_use_bound)):\n",
    "        st.write('At this pilot stage, each user may use GPT at most 3 times. Please feel free to email Ben at ben.chen@gsydney.edu.edu if you would like to use GPT again.')\n",
    "    \n",
    "    elif ((int(df_master.loc[0][\"Tick to use GPT\"]) > 0) & (len(df_master.loc[0][\"Your GPT API key\"]) < 20)):\n",
    "        st.write(\"You must enter a valid API key for GPT.\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        st.write(\"Your results will be available for download soon. The estimated waiting time is about 2-3 minutes.\")\n",
    "\n",
    "        #Upload placeholder record onto Google sheet\n",
    "        df_plaeceholdeer = pd.concat([df_google, df_master])\n",
    "        conn.update(worksheet=\"Sheet1\", data=df_plaeceholdeer, )\n",
    "\n",
    "        #Produce results\n",
    "\n",
    "        df_individual_output = run(df_master)\n",
    "\n",
    "        #Keep record on Google sheet\n",
    "        \n",
    "        df_master[\"Processed\"] = datetime.now()\n",
    "\n",
    "        df_master.pop(\"Your GPT API key\")\n",
    "        \n",
    "        df_to_update = pd.concat([df_google, df_master])\n",
    "        \n",
    "        conn.update(worksheet=\"Sheet1\", data=df_to_update, )\n",
    "\n",
    "        st.write(\"Your results are now available for download. Thank you for using the Empirical Legal Research Kickstarter.\")\n",
    "        \n",
    "        #Button for downloading results\n",
    "        output_name = df_master.loc[0, 'Your name'] + '_' + str(today_in_nums) + 'results'\n",
    "\n",
    "        csv_output = convert_df_to_csv(df_individual_output)\n",
    "        \n",
    "        ste.download_button(\n",
    "            label=\"Download your results as a CSV (for use in Excel etc)\", \n",
    "            data = csv_output,\n",
    "            file_name= output_name + '.csv', \n",
    "            mime= \"text/csv\", \n",
    "#            key='download-csv'\n",
    "        )\n",
    "\n",
    "        json_output = convert_df_to_json(df_individual_output)\n",
    "        \n",
    "        ste.download_button(\n",
    "            label=\"Download your results as a JSON\", \n",
    "            data = json_output,\n",
    "            file_name= output_name + '.json', \n",
    "            mime= \"application/json\", \n",
    "        )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f42b4295",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if keep_button:\n",
    "\n",
    "    #Using own GPT API key here\n",
    "\n",
    "    gpt_api_key_entry = ''\n",
    "    \n",
    "    df_master = create_df()\n",
    "\n",
    "    df_master.pop(\"Your GPT API key\")\n",
    "\n",
    "\n",
    "    responses_output_name = df_master.loc[0, 'Your name'] + '_' + str(today_in_nums) + '_responses'\n",
    "\n",
    "    #Produce a file to download\n",
    "\n",
    "    csv = convert_df_to_csv(df_master)\n",
    "    \n",
    "    ste.download_button(\n",
    "        label=\"Download as a CSV (for use in Excel etc)\", \n",
    "        data = csv,\n",
    "        file_name=responses_output_name + '.csv', \n",
    "        mime= \"text/csv\", \n",
    "#            key='download-csv'\n",
    "    )\n",
    "\n",
    "    json = convert_df_to_json(df_master)\n",
    "    \n",
    "    ste.download_button(\n",
    "        label=\"Download as a JSON\", \n",
    "        data = json,\n",
    "        file_name= responses_output_name + '.json', \n",
    "        mime= \"application/json\", \n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
